---
title: "SurveyMotion: Predicting completion conditions in mobile web surveys by using acceleration data"
subtitle: "MASS Workshop"
author: | 
  | Christoph Kern^a^, Jan Karem Hoehne^a,b^, Stephan Schlosser^c^ and Melanie Revilla^b^
  | ^a^University of Mannheim
  | ^b^RECSM-Universitat Pompeu Fabra
  | ^c^University of Goettingen
date: "`r Sys.Date()`"
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
output:
  pdf_document:
    toc: no
    df_print: kable
    fig_caption: true
    number_sections: true
bibliography: mass.bib
abstract: "Participation in web surveys via smartphones increased continuously in recent years. The reasons for this increase are a skyrocketing proportion of smartphone owners and an increase in mobile Internet access. However, research has shown that smartphone respondents are frequently distracted and/or multitasking, which may affect data quality. In this study, we therefore investigate if we can predict respondents' completion conditions (e.g., standing or walking) in mobile web surveys by employing machine learning techniques to compare response behavior between different motion groups. For this purpose, we use acceleration data of smartphone respondents -- measured by means of the JavaScript-based tool 'SurveyMotion (SM)' -- that were collected in a lab experiment which systematically varied the completion conditions. To predict completion conditions, we extract features from the acceleration data by aggregating over the repeated acceleration measurements on a page level. This results in a compact set of features that summarize the distribution (mean, quantiles, etc.) of acceleration values that were collected repeatedly for each respondent-page. Regularized regression and tree-based models were trained and tested using grouped cross-validation, reflecting the hierarchical structure of the data (pages nested in respondents). When building the prediction models, both a multiclass (sitting, standing, walking, climbing stairs) and a binary (moving, not moving) version of the outcome variable were considered. It becomes evident that the acceleration features can be used to build prediction models that almost perfectly discriminate between completion conditions on hold-out sets, with cross-validated ROC-AUCs of about 0.98 for the binary outcome. The evaluation results indicate that the trained prediction models can be used to precisely predict completion conditions in (new) mobile web surveys that collect SM data."
---

```{r, include = FALSE}
knitr::opts_knit$set(root.dir = "U:\\Forschung\\Article\\2019 - MASS",
              fig.pos = "H")
load("..\\src\\output1.Rdata")
load("..\\src\\output3.Rdata")
```

```{r, include = FALSE}
library(knitr)
library(tidyverse)
library(broom)
library(gridExtra)
library(ggmosaic)
library(caret)
```

# Introduction

Motivation: Smartphones allow respondents to take part in surveys irrespective of their location and situation, which gives rise to data quality concerns;

* Measurement in mobile web surveys challenged by distractions and multitasking [@Lynn2012; @Toninelli2016]
* Self-reports on distractions subject to error

Against this background, this study addresses the following research questions:

1. Can we accurately predict respondents completion conditions by using acceleration data?
2. Do respondents with different completion conditions (motion levels) differ in terms of response behavior?

Concept: Utilizing acceleration data from smartphone sensors and machine learning (ML) methods to infer completion conditions
  
## SurveyMotion

* JavaScript-based paradata tool [@Hohne2019]
* Measures the total acceleration (TA)
     + $TA = \sqrt{(a_x^2 + a_y^2 + a_z^2)}$
* Code can be implemented as an invisible, user-defined question in a web survey page

Figure 1 illustrates the data that can be collected with SurveyMotion. Total acceleration (y-axis) is plotted over time spent on a survey page (x-axis) for one randomly sampled participant of each group of the lab experiment (see section 2).

```{r echo = FALSE, warning = FALSE, message = FALSE, out.width = '75%', fig.align = "center", fig.cap = "Examples of total acceleration profiles"}
rawmotion <- grep("SM_[0123456789]", names(sm), value = TRUE)
row.names(sm) <- paste0("SM_", row.names(sm))

set.seed(25986)

p1 <- sm %>%
  filter(Group == 1 & page == "Matrix") %>%
  sample_n(1) %>%
  select(rawmotion) %>%
  rownames_to_column %>%
  gather(var, value, -rowname) %>%
  mutate(var = as.numeric(gsub("SM_", "", var))) %>%
  filter(var < 2000) %>%
  ggplot() + 
  geom_line(aes(x = var, y = value, group = rowname), alpha = 0.75, size = 0.2) + 
#  geom_smooth(aes(x = var, y = value), se = FALSE, color = "red", size = 0.25) +
  ylim(0, 5) +
  labs(x = "Time", y = "TA", title = "Sitting") +
  theme_light(base_size = 9) +
  theme(legend.position = "none")

p2 <- sm %>%
  filter(Group == 2 & page == "Matrix") %>%
  sample_n(1) %>%
  select(rawmotion) %>%
  rownames_to_column %>%
  gather(var, value, -rowname) %>%
  mutate(var = as.numeric(gsub("SM_", "", var))) %>%
  filter(var < 2000) %>%
  ggplot() + 
  geom_line(aes(x = var, y = value, group = rowname), alpha = 0.75, size = 0.2) + 
#  geom_smooth(aes(x = var, y = value), se = FALSE, color = "red", size = 0.25) +
  ylim(0, 5) +
  labs(x = "Time", y = "TA", title = "Standing") +
  theme_light(base_size = 9) +
  theme(legend.position = "none")

p3 <- sm %>%
  filter(Group == 3 & page == "Matrix") %>%
  sample_n(1) %>%
  select(rawmotion) %>%
  rownames_to_column %>%
  gather(var, value, -rowname) %>%
  mutate(var = as.numeric(gsub("SM_", "", var))) %>%
  filter(var < 2000) %>%
  ggplot() + 
  geom_line(aes(x = var, y = value, group = rowname), alpha = 0.75, size = 0.2) + 
#  geom_smooth(aes(x = var, y = value), se = FALSE, color = "red", size = 0.25) +
  ylim(0, 15) +
  labs(x = "Time", y = "TA", title = "Walking") +
  theme_light(base_size = 9) +
  theme(legend.position = "none")

p4 <- sm %>%
  filter(Group == 4 & page == "Matrix") %>%
  sample_n(1) %>%
  select(rawmotion) %>%
  rownames_to_column %>%
  gather(var, value, -rowname) %>%
  mutate(var = as.numeric(gsub("SM_", "", var))) %>%
  filter(var < 2000) %>%
  ggplot() + 
  geom_line(aes(x = var, y = value, group = rowname), alpha = 0.75, size = 0.2) + 
#  geom_smooth(aes(x = var, y = value), se = FALSE, color = "red", size = 0.25) +
  ylim(0, 15) +
  labs(x = "Time", y = "TA", title = "Climbing") +
  theme_light(base_size = 9) +
  theme(legend.position = "none")

grid.arrange(p1, p2, p3, p4, nrow = 2)
```

# Data

Lab experiment (train set)

* Data collected in August 2017 at the University of Goettingen [@Hohne2019]
* 89 university students
* Randomly assigned to one of four experimental groups
    + The first group (n = 22) was seated in front of a desk
    + The second group (n = 22) stood at a fixed point
    + The third group (n = 23) walked along an aisle
    + The fourth group (n = 22) climbed stairs

Cross-sectional web survey (test set)

* Data collected in December 2017 at the University of Goettingen [@Schlosser2018]
* 2,357 respondents
* 61.6% smartphone respondents
* SM data available for 97,2% of smartphone respondents

Data preparation

* Unit of observation: Respondent-pages
1. Outcome
    * 4 class outcome: sitting, standing, walking, climbing stairs
    * 2 class outcome: moving (walking, climbing stairs), not moving (sitting, standing)
2. Predictors
    * Aggregated TA measurements (summary statistics over repeated acceleration values)
    * Raw TA measurements

```{r include = FALSE}
kable(sm[c(1:4,17:18), c(1,3,13113:13117)], digits = 3, caption = "Training data example")
```

# Preliminary results

## Model training (lab data)

Model building and evaluation

* ML methods
    + Elastic net (GLMnet; @Friedman2010)
    + Conditional Inference Trees (CTREE; @Hothorn2015)
    + Random Forests and Extremely Randomized Trees (RF; @Wright2017)
    + Extreme Gradient Boosting (XGBoost; @Chen2016)
* Feature groups
    + Only aggregated TA features
    + Aggregated and raw TA values (robustness check, not reported)
* 10-Fold Cross-Validation (grouped by respondent IDs)

Prediction performance

* 4 class outcome
    + Cross-Validated ROC-AUCs of 0.9 and above
    + Best performance for random forest and GLMnet
* 2 class outcome
    + Cross-Validated ROC-AUCs of 0.98 and above
    + Almost perfect discrimination for all ML methods

Figure 2 and 3 display cross-validated performance in the training set for both outcomes and each ML method. More specifically, the distribution of ROC-AUC and Logloss over all hold-out sets is plotted, where high ROC-AUC (with a maximum of 1 and 0.5 for a non-informative model) and low logLoss (0, no upper bound) indicate better performance.

```{r echo = FALSE, out.width = '60%', fig.align = "center", fig.cap = "CV results (4 class outcome)"}
p1 <- ggplot(resamp_l1) +
  geom_boxplot(aes(y = AUC, x = fct_rev(model), fill = model)) +
  ylim(0.5, 1) +
  labs(x = "") +
  labs(y = "ROC-AUC") +
  coord_flip() + 
  theme_light() +
  theme(legend.position = "none")

p2 <- ggplot(resamp_l1) +
  geom_boxplot(aes(y = logLoss, x = fct_rev(model), fill = model)) +
  labs(x = "") +
  labs(y = "logLoss") +
  coord_flip() + 
  theme_light() +
  theme(legend.position = "none")

grid.arrange(p1, p2, nrow = 1)
```

```{r echo = FALSE, out.width = '60%', fig.align = "center", fig.cap = "CV results (2 class outcome)"}
p3 <- ggplot(resamp_l2) +
  geom_boxplot(aes(y = ROC, x = fct_rev(model), fill = model)) +
  ylim(0.5, 1) +
  labs(x = "") +
  labs(y = "ROC-AUC") +
  coord_flip() + 
  theme_light() +
  theme(legend.position = "none")

p4 <- ggplot(resamp_l2) +
  geom_boxplot(aes(y = logLoss, x = fct_rev(model), fill = model)) +
  labs(x = "") +
  labs(y = "logLoss") +
  coord_flip() + 
  theme_light() +
  theme(legend.position = "none")

grid.arrange(p3, p4, nrow = 1)
```

Confusion tables

* Table 1 and 2 cross-tabulate predicted (rows) and true (columns) classes, averaged over hold-out sets
* High accuracy for both outcomes (correct predictions in main diagonal)
* Some misclassifications within moving (walking vs. climbing) and non-moving (sitting vs. standing) conditions

```{r echo = FALSE}
dat <- as.data.frame.matrix(confusionMatrix(rf_l1)$table)

kable(dat, digits = 3, caption = "RF confusion matrix (4 class outcome)")
```

```{r echo = FALSE}
dat <- as.data.frame.matrix(confusionMatrix(rf_l2)$table)

kable(dat, digits = 3, caption = "RF confusion matrix (2 class outcome)")
```

## Prediction 

**Step 1**: Data check

Figure 4 compares the distribution of selected (aggregated) TA features between lab (training) and field (test) data.

```{r echo = FALSE, warning = FALSE, out.width = '75%', fig.align = "center", fig.cap = "Distribution of aggregated TA measurements"}

gt1 <- ggplot(sm) +
  geom_density(aes(x = SM_mean, color = D_group)) +
  xlim(0, 4) +
  labs(title = "Training data") +
  theme_light(base_size = 9)  +
  theme(legend.position = "none")

gt2 <- ggplot(sm) +
  geom_density(aes(x = SM_var, color = D_group)) +
  xlim(0, 2) +
  labs(title = "") +
  theme_light(base_size = 9)  +
  theme(legend.position = "none")

gt3 <- ggplot(sm) +
  geom_density(aes(x = SM_max, color = D_group)) +
  xlim(0, 20) +
  labs(title = "") +
  theme_light(base_size = 9)  +
  theme(legend.position = c(0.75, 0.8),
        legend.text = element_text(size = 6),
        legend.title = element_blank())

gt4 <- ggplot(G_test_long1) +
  geom_density(aes(x = SM_mean)) +
  xlim(0, 4) +
  labs(title = "Test data") +
  theme_light(base_size = 9)

gt5 <- ggplot(G_test_long1) +
  geom_density(aes(x = SM_var)) +
  xlim(0, 2) +
  labs(title = "") +
  theme_light(base_size = 9)

gt6 <- ggplot(G_test_long1) +
  geom_density(aes(x = SM_max)) +
  xlim(0, 20) +
  labs(title = "") +
  theme_light(base_size = 9)

grid.arrange(gt1, gt2, gt3, gt4, gt5, gt6, nrow = 2)
```

**Step 2**: Class prediction

Figure 5 displays the proportions of predicted completion conditions in the test data based on random forest models (trained with lab data).

```{r echo = FALSE, out.width = '70%', fig.align = "center", fig.cap = "Predicted completion conditions (RF)"}
g5 <- ggplot(G_test_long1) +
  geom_mosaic(aes(x = product(p_rf_l1, page), fill = p_rf_l1), na.rm = TRUE) +
  labs(y = "", x = "", title = "4 class outcome") +
  theme_light()  +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45,
                                hjust = 1,
                                vjust = 1))

g6 <- ggplot(G_test_long1) +
  geom_mosaic(aes(x = product(p_rf_l2, page), fill = p_rf_l2), na.rm = TRUE) +
  labs(y = "", x = "", title = "2 class outcome") +
  theme_light()  +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45,
                                hjust = 1,
                                vjust = 1))

grid.arrange(g5, g6, nrow = 1)
```

**Step 3.1**: Compare groups (page level)

Compare "data quality proxies" between predicted completion conditions (moving vs. non-moving)\
Unit of observation: Respondent-pages

Figure 6 compares completion times (in seconds) for eight single question pages and two survey pages with grid questions between predicted completion conditions (moving, not moving). Mean completion times for both groups and corresponding t-test results are shown in Table 3.

```{r echo = FALSE, warning = FALSE, out.width = '70%', fig.align = "center", fig.cap = "Completion times by predicted completion conditions"}
g7 <- G_test_long1 %>%
  drop_na(p_rf_l2) %>%
  filter(page %in% c("Single_E1", "Single_E2", "Single_E3", "Single_E4", "Single_E5", "Single_E6", "Single_E7", "Single_E8")) %>%
  ggplot() +
  geom_boxplot(aes(y = Completion_Time_sc, x = page, color = p_rf_l2), outlier.size = 0.1) +
  labs(y = "Completion Time", x = "") +
  theme_light() +
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 45,
                                hjust = 1,
                                vjust = 1))

g8 <- G_test_long1 %>%
  drop_na(p_rf_l2) %>%
  filter(page %in% c("Matrix_1", "Matrix_2")) %>%
  ggplot() +
  geom_boxplot(aes(y = Completion_Time_sc, x = page, color = p_rf_l2), outlier.size = 0.1) +
  labs(y = "", x = "") +
  guides(color = guide_legend(title = "")) +
  theme_light() +
  theme(axis.text.x = element_text(angle = 45,
                                hjust = 1,
                                vjust = 1))

grid.arrange(g7, g8, nrow = 1)
```

```{r echo = FALSE, warning = FALSE}
t1 <- G_test_long1 %>%
  filter(page %in% c("Single_E1", "Single_E2", "Single_E3", "Single_E4", "Single_E5", "Single_E6", "Single_E7", "Single_E8")) %>%
  t.test(Completion_Time_sc ~ p_rf_l2, data = .) %>%
  tidy(.)

t2 <- G_test_long1 %>%
  filter(page %in% c("Matrix_1", "Matrix_2")) %>%
  t.test(Completion_Time_sc ~ p_rf_l2, data = .) %>%
  tidy(.)

dat <- rbind(t1[, 2:5], t2[, 2:5])
dat <- add_column(dat, var = c("Single", "Grid"), .before = 1)
colnames(dat) <- c("", "m(moving)", "m(not moving)", "statistic", "p.value")

kable(dat, digits = 3, caption = "Completion times by predicted completion conditions")
```

**Step 3.2**: Compare groups (respondent level)

Compare "data quality proxies" between predicted completion conditions (moving vs. non-moving)\
Unit of observation: Respondents -- classification based on the most common page level category

Table 4 displays proportions of respondents who passed the attention check and means for  multitasking items for both motion groups as well as $\chi^2$ and t-test results.

* Attention check (AC): 0 = "not passed", 1 "passed"
* Multitasking_1: Self reported, 0 = "stayed on survey pages", 1 "left survey pages"
* Multitasking_2: Self reported, sum of other activities during survey

```{r include = FALSE}
G_test_wide %>%
  drop_na(p_rf_l2m) %>%
  group_by(p_rf_l2m) %>%
  rename(p_rf = p_rf_l2m) %>%
  summarise(E1_SF_OFF = mean(E1_SF_OFF), E2_SF_OFF = mean(E2_SF_OFF), E1_SF_OFF = mean(E3_SF_OFF), E4_SF_OFF = mean(E4_SF_OFF), E5_SF_OFF = mean(E5_SF_OFF), E6_SF_OFF = mean(E6_SF_OFF), E7_SF_OFF = mean(E7_SF_OFF), E8_SF_OFF = mean(E8_SF_OFF), M_1_SF_OFF = mean(M_1_SF_OFF), M_2_SF_OFF = mean(M_2_SF_OFF))
```

```{r echo = FALSE, warning = FALSE}
d <- G_test_wide %>%
  drop_na(p_rf_l2m) %>%
  group_by(p_rf_l2m) %>%
  summarise(AC = mean(AC_Answ, na.rm = T), Multitasking_1 = mean(Multitasking_1_Answ, na.rm = T), Multitasking_2 = mean(Multitasking_2_Answ, na.rm = T))

t1 <- tidy(chisq.test(G_test_wide$p_rf_l2m, G_test_wide$AC_Answ))
t2 <- tidy(chisq.test(G_test_wide$p_rf_l2m, G_test_wide$Multitasking_1_Answ, simulate.p.value = T))
t3 <- tidy(t.test(Multitasking_2_Answ ~ p_rf_l2m, data = G_test_wide))

tab1 <- t(d[,2:4])
tab2 <- rbind(t1[1:2], t2[1:2], t3[4:5])
dat <- cbind(tab1, tab2)
colnames(dat) <- c("m(moving)", "m(not moving)", "statistic", "p.value")

kable(dat, digits = 3, caption = "Attention check and multitasking by predicted completion conditions")
```

Table 5 summarizes survey evaluation items between predicted completion conditions and reports corresponding t-test results.

* Motivation: Motivation to participate in survey, 1 = "very high", ..., 5 = "very low"
* Boring, ..., Monotonous: Survey evaluation, 7 point semantic differential scale

```{r echo = FALSE, warning = FALSE}
t1 <- tidy(t.test(Motivation_Answ_1 ~ p_rf_l2m, data = G_test_wide))
t2 <- tidy(t.test(SemDiff_Answ_1 ~ p_rf_l2m, data = G_test_wide))
t3 <- tidy(t.test(SemDiff_Answ_2 ~ p_rf_l2m, data = G_test_wide))
t4 <- tidy(t.test(SemDiff_Answ_3 ~ p_rf_l2m, data = G_test_wide))
t5 <- tidy(t.test(SemDiff_Answ_4 ~ p_rf_l2m, data = G_test_wide))
t6 <- tidy(t.test(SemDiff_Answ_5 ~ p_rf_l2m, data = G_test_wide))

dat <- rbind(t1[, 2:5], t2[, 2:5], t3[, 2:5], t4[, 2:5], t5[, 2:5], t6[, 2:5])
dat <- add_column(dat, var = c("Motivation", "Boring", "Difficult", "Exhausting", "Complicated", "Monotonous"), .before = 1)
colnames(dat) <- c("", "m(moving)", "m(not moving)", "statistic", "p.value")

kable(dat, digits = 3, caption = "Survey evaluation by predicted completion conditions")
```

# Discussion 

* Summary
     + High cross-validated prediction accuracy for 4 class and 2 class outcome in training data
     + Low rate of respondents with predicted high motion levels (e.g., walking) in test data
     + Almost no differences in terms of data quality proxies between motion groups
* Next steps
     + Add further data quality proxies for group comparisons (item nonresponse, response styles)
     + Compare predicted classes with simple mean split (high vs. low average TA in test data)

# References